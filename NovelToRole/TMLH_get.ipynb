{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.获取小说资源\n",
    "\n",
    "自行下载epub文件，在此转换为txt格式并合并为一个文件，已有txt格式则忽略这步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ebooklib import epub\n",
    "# from bs4 import BeautifulSoup\n",
    "# import os\n",
    "\n",
    "# def extract_text_from_epub(file_path):\n",
    "#     book = epub.read_epub(file_path)\n",
    "#     text_content = []\n",
    "#     for item in book.items:\n",
    "#         if item.media_type == 'application/xhtml+xml':\n",
    "#             soup = BeautifulSoup(item.content,'html.parser')\n",
    "#             text_content.append(soup.get_text())\n",
    "#     return \"\\n\".join(text_content)\n",
    "\n",
    "# def merge_epubs_to_txt(epub_files, output_txt_file):\n",
    "#     with open(output_txt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#         for file_name in os.listdir(epub_files):\n",
    "#             if file_name.endswith('.epub'):\n",
    "#                 file_path = os.path.join(epub_files,file_name)\n",
    "#                 print(f\"Porcess {file_name}...\")\n",
    "#                 text = extract_text_from_epub(file_path)\n",
    "#                 f.write(text + \"\\n\\n\")\n",
    "\n",
    "\n",
    "# # 使用示例\n",
    "# epub_files = \"./novel/败犬1-6-epub\"\n",
    "# output_txt_file = \"TooManyLosingHeroines.txt\"   \n",
    "# merge_epubs_to_txt(epub_files, output_txt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.小说切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择你要处理的小说，接下来的保存路径都将使用小说名\n",
    "novel_name = \"Honglou-full\"\n",
    "input_txt_name = f\"./novel/{novel_name}.txt\"\n",
    "save_folder = f\"./extract/{novel_name}\"\n",
    "\n",
    "# target_role: 要抽取的人物名称\n",
    "# 支持空字符串(默认前三个)或者 list[str] ，如果出错默认保存第一个\n",
    "target_role = [\"黛玉\", \"宝玉\", \"宝钗\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0 第一回  甄士隐梦幻\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "else:\n",
    "    print('注意，文件夹',save_folder,'已经存在')\n",
    "\n",
    "raw_text = open(input_txt_name, encoding='utf-8').read()\n",
    "\n",
    "# 将文本按章节切分\n",
    "chapters = []\n",
    "chapter_contents = []\n",
    "\n",
    "for line in raw_text.split('\\n'):\n",
    "    Flag = False\n",
    "    if line.strip().startswith(\"～第\"):\n",
    "        # 遇到章节标题,将之前章节内容添加到结果列表\n",
    "\n",
    "        head = line.strip()\n",
    "        # print(head)\n",
    "        head = head[:min(10,len(head))]\n",
    "        if head.find('败',1)>0:\n",
    "            # print(head)\n",
    "            Flag = True\n",
    "\n",
    "    if Flag:\n",
    "        if chapter_contents:\n",
    "            chapters.append('\\n'.join(chapter_contents))\n",
    "            chapter_contents = []\n",
    "        # 记录当前章节标题\n",
    "        # chapters.append(line)\n",
    "    else:\n",
    "        # 累积章节内容\n",
    "        chapter_contents.append(line)\n",
    "\n",
    "# 添加最后一个章节内容\n",
    "if chapter_contents:\n",
    "    chapters.append('\\n'.join(chapter_contents))\n",
    "# 检查结果\n",
    "print(len(chapters))\n",
    "for i,ch in enumerate(chapters):\n",
    "    print(i,ch[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title  定义divide函数，用来切分超长文本\n",
    "def divide_str(s, sep=[\"\\n\", \".\", \"。\"]):\n",
    "    mid_len = len(s) // 2  # 中心点位置\n",
    "    best_sep_pos = len(s) + 1  # 最接近中心点的分隔符位置\n",
    "    best_sep = None  # 最接近中心点的分隔符\n",
    "    for curr_sep in sep:\n",
    "        sep_pos = s.rfind(curr_sep, 0, mid_len)  # 从中心点往左找分隔符\n",
    "        if sep_pos > 0 and abs(sep_pos - mid_len) < abs(best_sep_pos - mid_len):\n",
    "            best_sep_pos = sep_pos\n",
    "            best_sep = curr_sep\n",
    "    if not best_sep:  # 没有找到分隔符\n",
    "        return s, \"\"\n",
    "    return s[: best_sep_pos + 1], s[best_sep_pos + 1 :]\n",
    "\n",
    "\n",
    "def strong_divide(s):\n",
    "    left, right = divide_str(s)\n",
    "\n",
    "    if right != \"\":\n",
    "        return left, right\n",
    "\n",
    "    whole_sep = [\n",
    "        \"\\n\",\n",
    "        \".\",\n",
    "        \"，\",\n",
    "        \"、\",\n",
    "        \";\",\n",
    "        \",\",\n",
    "        \"；\",\n",
    "        \"：\",\n",
    "        \"！\",\n",
    "        \"？\",\n",
    "        \"(\",\n",
    "        \")\",\n",
    "        \"”\",\n",
    "        \"“\",\n",
    "        \"’\",\n",
    "        \"‘\",\n",
    "        \"[\",\n",
    "        \"]\",\n",
    "        \"{\",\n",
    "        \"}\",\n",
    "        \"<\",\n",
    "        \">\",\n",
    "        \"/\",\n",
    "        \"\"\"''', '|', '-', '=', '+', '*', '%', \\\n",
    "               '$', \"\"\"  #''', '@', '&', '^', '_', '`', '~',\\\n",
    "        \"·\",\n",
    "        \"…\",\n",
    "    ]\n",
    "    left, right = divide_str(s, sep=whole_sep)\n",
    "\n",
    "    if right != \"\":\n",
    "        return left, right\n",
    "\n",
    "    mid_len = len(s) // 2\n",
    "    return s[:mid_len], s[mid_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959\n",
      "黛玉一一的都答应着。只见一个丫鬟来回：“老太太那里传晚饭了！”王夫人忙携黛玉从后房门由后廊往西，出了角门，是一条南北宽夹道。南边是倒座三间小小抱厦厅，北边立着一个粉油大影壁，后有一半大门，小小一所房室。王夫人笑指向黛玉道：“这是你凤姐姐的屋子，回来你好往这里找她来，少什么东西，你只管和她说就是了。”这院门上也有四五个才总角的小厮，都垂手侍立。王夫人遂携黛玉穿过一个东西穿堂，便是贾母的后院了。于是，进入后房门，已有多人在此伺候，见王夫人来了，方安设桌椅。贾珠之妻李氏捧饭，熙凤安箸，王夫人进羹。贾母正面榻上独坐，两边四张空椅，熙凤忙拉了黛玉在左边第一张椅上坐了。黛玉十分推让。贾母笑道：“你舅母和嫂子们不在这里吃饭。你是客，原应如此坐的。”黛玉方告了座，坐了。贾母命王夫人坐了。迎春姊妹三个告了座，方上来。迎春便坐右手第一，探春左第二，惜春右第二。旁边丫鬟执着拂尘、漱盂、巾帕。李、凤二人立于案旁布让。外间伺候之媳妇丫鬟虽多，却连一声咳嗽不闻。寂然饭毕，各有丫鬟用小茶盘捧上茶来。当日林如海教女以惜福养身，云饭后务待饭粒咽尽，过一时再吃茶，方不伤脾胃。今黛玉见了这里许多事情不合家中之式，不得不随的，少不得一一的改过来，因而接了茶。早有人又捧过漱盂来，黛玉也照样漱了口。然后盥手毕，又捧上茶来，方是吃的茶。贾母便说：“你们去罢，让我们自在说话儿。”王夫人听了，忙起身，又说了两句闲话，方引李、凤二人去了。贾母因问黛玉念何书。黛玉道：“只刚念了《四书》。”黛玉又问姊妹们读何书。贾母道：“读的是什么书，不过是认得两个字，不是睁眼的瞎子罢了！”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title 以1500 token为限，切分chunk，输出总chunk数量\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "max_token_len = 1500\n",
    "chunk_text = []\n",
    "\n",
    "\n",
    "for chapter in chapters:\n",
    "\n",
    "    split_text = chapter.split(\"\\n\")\n",
    "\n",
    "    curr_len = 0\n",
    "    curr_chunk = \"\"\n",
    "\n",
    "    tmp = []\n",
    "\n",
    "    for line in split_text:\n",
    "        line_len = len(enc.encode(line))\n",
    "\n",
    "        if line_len <= max_token_len - 5:\n",
    "            tmp.append(line)\n",
    "        else:\n",
    "            # print('divide line with length = ', line_len)\n",
    "            path = [line]\n",
    "            tmp_res = []\n",
    "\n",
    "            while path:\n",
    "                my_str = path.pop()\n",
    "                left, right = strong_divide(my_str)\n",
    "\n",
    "                len_left = len(enc.encode(left))\n",
    "                len_right = len(enc.encode(right))\n",
    "\n",
    "                if len_left > max_token_len - 15:\n",
    "                    path.append(left)\n",
    "                else:\n",
    "                    tmp_res.append(left)\n",
    "\n",
    "                if len_right > max_token_len - 15:\n",
    "                    path.append(right)\n",
    "                else:\n",
    "                    tmp_res.append(right)\n",
    "\n",
    "            for line in tmp_res:\n",
    "                tmp.append(line)\n",
    "\n",
    "    split_text = tmp\n",
    "\n",
    "    for line in split_text:\n",
    "        line_len = len(enc.encode(line))\n",
    "\n",
    "        if line_len > max_token_len:\n",
    "            print(\"warning line_len = \", line_len)\n",
    "\n",
    "        if curr_len + line_len <= max_token_len:\n",
    "            curr_chunk += line\n",
    "            curr_chunk += \"\\n\"\n",
    "            curr_len += line_len\n",
    "            curr_len += 1\n",
    "        else:\n",
    "            chunk_text.append(curr_chunk)\n",
    "            curr_chunk = line\n",
    "            curr_len = line_len\n",
    "\n",
    "    if curr_chunk:\n",
    "        chunk_text.append(curr_chunk)\n",
    "\n",
    "    # break\n",
    "\n",
    "print(len(chunk_text))\n",
    "print(chunk_text[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.重组小说\n",
    "    将小说重组为人物对话和剧情摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_community kor\n",
    "# !pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "# 设置你自己的LLM key与model\n",
    "key = os.getenv(\"OPENAI_API_KEY\", \"your_api_key\")\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=model, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 仅仅抽取dialogue的部分\n",
    "\n",
    "# @title 抽取role,dialogue,action\n",
    "\n",
    "schema = Object(\n",
    "    id=\"script\",\n",
    "    description='''Adapted from the novel into script,\n",
    "    The main character,“温水”, refers to himself as “我” ''',\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id=\"role\",\n",
    "            description=\"The character who is speaking, use context to predict the name of the role.\",\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"dialogue\",\n",
    "            description=\"The dialogue spoken by the characters in the sentence\",\n",
    "        ),\n",
    "        Text(\n",
    "            id =\"action\",\n",
    "            descrtption = '''The actions performed by the characters in the text, A high-level summary of a character's behavior. action equals \"对话\" or \"独白\" or \"动作\", \n",
    "            equals \"对话\" if it's sentence in [], equals \"独白\" elif it's a psychological monologue not in [], equals \"动作\" else\n",
    "            ''',\n",
    "        ),\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"``八奈见不知何时来到我身旁，用手肘轻轻地顶我。\n",
    "「喔，烧盐同学好像喜欢绫野的样子。」\n",
    "「是喔。真是意外的组合呢。」\n",
    "「我和他们国中时同校，不过他们好像从国小就常常在一起。」\n",
    "「所以说，就和青梅竹马差不多啰。」\n",
    "青梅竹马……在八奈见眼中是这样吗？\n",
    "对着无法理解的我，八奈见无奈地耸了耸肩。\n",
    "「听我说，温水，女生可以分成两大类。如果不是青梅竹马，就是狐狸精。」\n",
    "原来如此，真豪爽的分类法。八奈见用严厉的表情看着我。``\"\"\",\n",
    "            [\n",
    "                {\"role\":\"八奈见\",\"dialogue\":\"八奈见不知何时来到我身旁，用手肘轻轻地顶我\",\"action\":\"动作\",},\n",
    "                {\"role\": \"八奈见\", \"dialogue\": \"喔，烧盐同学好像喜欢绫野的样子\",\"action\":\"对话\",},\n",
    "                {\"role\": \"温水\", \"dialogue\": \"是喔。真是意外的组合呢。\",\"action\":\"对话\",},\n",
    "                {\n",
    "                    \"role\": \"温水\",\n",
    "                    \"dialogue\": \"我和他们国中时同校，不过他们好像从国小就常常在一起\",\n",
    "                    \"action\":\"对话\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"温水\",\n",
    "                    \"dialogue\": \"青梅竹马……在八奈见眼中是这样吗？\",\n",
    "                    \"action\":\"独白\",\n",
    "                },\n",
    "                {\"role\": \"八奈见\", \"dialogue\": \"所以说，就和青梅竹马差不多啰\",\"action\":\"对话\",},\n",
    "                {\n",
    "                    \"role\": \"八奈见\",\n",
    "                    \"dialogue\": \"听我说，温水，女生可以分成两大类。如果不是青梅竹马，就是狐狸精\",\n",
    "                    \"action\":\"对话\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"温水\",\n",
    "                    \"dialogue\": \"原来如此，真豪爽的分类法\",\n",
    "                    \"action\":\"独白\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    many=True,\n",
    ")\n",
    "chain = create_extraction_chain(llm, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'script': [{'role': '士隐', 'dialogue': '一日，炎夏永昼，士隐于书房闲坐，至手倦拋书，伏几少憩，不觉朦胧睡去', 'action': '独白'}, {'role': '道人', 'dialogue': '你携了这蠢物，意欲何往？', 'action': '对话'}, {'role': '僧', 'dialogue': '你放心，如今现有一段风流公案正该了结。这一干风流冤家，尚未投胎入世。趁此机会，就将此蠢物夹带于中，使他去经历经历', 'action': '对话'}, {'role': '道人', 'dialogue': '原来近日风流冤孽又将造劫历世去不成？但不知落于何方何处？', 'action': '对话'}, {'role': '僧', 'dialogue': '此事说来好笑，竟是千古未闻的罕事：只因西方灵河岸上三生石畔有绛珠草一株，时有赤瑕宫神瑛侍者，日以甘露灌溉，这绛珠草便得久延岁月', 'action': '对话'}, {'role': '僧', 'dialogue': '后来既受天地精华，复得雨露滋养，遂得脱却草胎木质，得换人形，仅修成个女体，终日游于离恨天外，饥则食蜜青果为膳，渴则饮灌愁海水为汤', 'action': '对话'}, {'role': '僧', 'dialogue': '只因尚未酬报灌溉之德，故其五内便郁结着一段缠绵不尽之意', 'action': '对话'}, {'role': '僧', 'dialogue': '恰近日这神瑛侍者凡心偶炽，乘此昌明太平朝世，意欲下凡造历幻缘，已在警幻仙子案前挂了号', 'action': '对话'}, {'role': '僧', 'dialogue': '警幻亦曾问及，灌溉之情未偿，趁此倒可了结的', 'action': '对话'}, {'role': '绛珠仙子', 'dialogue': '他是甘露之惠，我并无此水可还。他既下世为人，我也去下世为人，但把我一生所有的眼泪还他，也偿还得过他了', 'action': '对话'}, {'role': '道人', 'dialogue': '果是罕闻。实未闻有‘还泪’之说。想来这一段故事，比历来风月事故更加琐碎细腻了', 'action': '对话'}, {'role': '僧', 'dialogue': '历来几个风流人物，不过传其大概，以及诗词篇章而已；至家庭闺阁中一饮一食，总未述记', 'action': '对话'}, {'role': '道人', 'dialogue': '趁此你我何不也去下世度脱几个，岂不是一场功德？', 'action': '对话'}, {'role': '僧', 'dialogue': '正合吾意。你且同我到警幻仙子宫中，将蠢物交割清楚，待这一干风流孽鬼下世已完，你我再去', 'action': '对话'}, {'role': '士隐', 'dialogue': '俱听得明白，但不知所云“蠢物”系何东西。遂不禁上前施礼，笑问道：“二仙师请了。”', 'action': '独白'}, {'role': '僧', 'dialogue': '也忙答礼相问', 'action': '对话'}, {'role': '士隐', 'dialogue': '适闻仙师所谈因果，实人世罕闻者。但弟子愚浊，不能洞悉明白，若蒙大开痴顽，备细一闻，弟子则洗耳谛听，稍能警省，亦可免沉伦之苦', 'action': '独白'}, {'role': '二仙', 'dialogue': '此乃玄机不可预泄者。到那时，只不要忘了我二人，便可跳出火坑矣', 'action': '对话'}, {'role': '士隐', 'dialogue': '玄机不可预泄，但适云‘蠢物’，不知为何，或可一见否？', 'action': '对话'}, {'role': '僧', 'dialogue': '若问此物，倒有一面之缘', 'action': '对话'}, {'role': '僧', 'dialogue': '说着，取出递与士隐', 'action': '动作'}, {'role': '士隐', 'dialogue': '接了看时，原来是块鲜明美玉，上面字迹分明，镌着“通灵宝玉”四字，后面还有几行小字', 'action': '独白'}, {'role': '僧', 'dialogue': '已到幻境！', 'action': '对话'}, {'role': '僧', 'dialogue': '便强从手中夺了去，与道人竟过一大石牌坊，上书四个大字，乃是“太虚幻境”', 'action': '动作'}, {'role': '道人', 'dialogue': '既如此，便随你去来', 'action': '对话'}]}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_chunk_id = 3\n",
    "response = chain.invoke({\"text\":f\"``{chunk_text[test_chunk_id]}\"})\n",
    "print(response[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Summarize the key points of the following text in a concise way, using bullet points.\n",
    "\"\"\"\n",
    "\n",
    "q_example = \"\"\"###\n",
    "Text:\n",
    "洪七公、周伯通、郭靖、黄蓉四人乘了小船，向西驶往陆地。郭靖坐在船尾扳桨，黄蓉不住向周伯通详问骑鲨游海之事，周伯通兴起，当场就要设法捕捉鲨鱼，与黄蓉大玩一场。\n",
    "郭靖见师父脸色不对，问道：“你老人家觉得怎样”洪七公不答，气喘连连，声息粗重。他被欧阳锋以“透骨打穴法”点中之后，穴道虽已解开，内伤却又加深了一层。黄蓉喂他服了几颗九花玉露丸，痛楚稍减，气喘仍是甚急。\n",
    "老顽童不顾别人死活，仍是嚷着要下海捉鱼，黄蓉却已知不妥，向他连使眼色，要他安安静静的，别吵得洪七公心烦。周伯通并不理会，只闹个不休。黄蓉皱眉道：“你要捉鲨鱼，又没饵引得鱼来，吵些甚么”\n",
    "\n",
    "Summarize in BULLET POINTS form:\n",
    "\"\"\"\n",
    "\n",
    "a_example = \"\"\"\n",
    "- 洪七公等四人乘船西行,洪七公因受内伤加重而气喘不止\n",
    "- 周伯通要捉鲨鱼玩,被黄蓉阻止以免掀翻小船\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charles0618\\AppData\\Local\\Temp\\ipykernel_32624\\254159305.py:16: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(messages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 士隐在书房中打盹，梦见一僧一道谈论风流公案。\n",
      "- 僧人提到要将“蠢物”夹带于风流冤家中，以便经历。\n",
      "- 讨论中提到西方灵河岸上的绛珠草和神瑛侍者的故事。\n",
      "- 神瑛侍者因凡心炽热，欲下凡造历幻缘，绛珠仙子愿意还泪以报恩。\n",
      "- 僧人和道人计划去下世度脱风流冤家。\n",
      "- 甄士隐听到谈话，询问“蠢物”是什么，僧人给他一块“通灵宝玉”。\n",
      "- 僧人告知已到幻境，并带领道人过石牌坊，牌坊上写有“太虚幻境”。\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=q_example),\n",
    "    AIMessage(content=a_example),\n",
    "]\n",
    "\n",
    "\n",
    "new_input = f\"\"\"###\n",
    "Text:\n",
    "{chunk_text[test_chunk_id]}\n",
    "\n",
    "Summarize in BULLET POINTS form:\"\"\"\n",
    "\n",
    "messages.append(HumanMessage(content=new_input))\n",
    "\n",
    "response = llm(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [3:54:06<00:00, 14.65s/it]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 最贵的一步，这里只处理几个chunk作为测试\n",
    "for i in tqdm(range(len(chunk_text))):\n",
    "    save_name = os.path.join(save_folder, f\"{i}_dialogue.txt\")\n",
    "\n",
    "    if not os.path.exists(save_name) or os.path.getsize(save_name) < 5:\n",
    "        if os.path.exists(save_name):\n",
    "            print(\"re-generate dialogue id = \", i)\n",
    "        query_text = f\"``{chunk_text[i]}``\"\n",
    "        # dialogue_response = chain.run( query_text )[\"data\"]\n",
    "        dialogue_response = chain.invoke({\"text\": f\"``{chunk_text[i]}``\"})[\"data\"]\n",
    "        with open(save_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            if \"script\" not in dialogue_response:\n",
    "                print('Error: response does not contain key \"script\"')\n",
    "            else:\n",
    "                for chat in dialogue_response[\"script\"]:\n",
    "                    json_str = json.dumps(chat, ensure_ascii=False)\n",
    "                    f.write(json_str + \"\\n\")\n",
    "\n",
    "    save_name_sum = os.path.join(save_folder, f\"{i}_sum.txt\")\n",
    "\n",
    "    if not os.path.exists(save_name_sum) or os.path.getsize(save_name_sum) < 5:\n",
    "        if os.path.exists(save_name_sum):\n",
    "            print(\"re-summarize id = \", i)\n",
    "        # dealing with summarize\n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=q_example),\n",
    "            AIMessage(content=a_example),\n",
    "        ]\n",
    "\n",
    "        new_input = f\"###\\nText:\\n{chunk_text[ i ]}\\nSummarize in BULLET POINTS form:\"\n",
    "\n",
    "        messages.append(HumanMessage(content=new_input))\n",
    "\n",
    "        summarize_response = llm(messages).content\n",
    "\n",
    "        with open(save_name_sum, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summarize_response)\n",
    "\n",
    "    raw_text_save_name = os.path.join(save_folder, f\"{i}_raw.txt\")\n",
    "\n",
    "    if (\n",
    "        not os.path.exists(raw_text_save_name)\n",
    "        or os.path.getsize(raw_text_save_name) < 5\n",
    "    ):\n",
    "        with open(raw_text_save_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(chunk_text[i])\n",
    "    # TODO for test\n",
    "    # if i > 3:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将得到的raw,dialogue,sum组合为规格的json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder_path = f\"./reorganized/{novel_name}\"\n",
    "# chunk所在文件夹，请以_raw结尾\n",
    "folder_path = f\"./extract/{novel_name}\"\n",
    "# 故事名字，默认为_raw之前的名字\n",
    "story_name_en = novel_name\n",
    "\n",
    "save_jsonl_path = f\"{save_folder_path}/reorganized_{story_name_en}.jsonl\"\n",
    "save_txt_path = f\"{save_folder_path}/reorganized_{story_name_en}.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959\n"
     ]
    }
   ],
   "source": [
    "chunk_text = [\"\"] * (\n",
    "    sum([1 for file_name in os.listdir(folder_path) if file_name.endswith(\"_sum.txt\")])\n",
    ")\n",
    "\n",
    "# 遍历文件夹中的文件\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\"_raw.txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # 提取文件名中的 i\n",
    "        i = int(file_name.split(\"_\")[0])\n",
    "\n",
    "        # 打开文件并读取内容\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # 将文件内容添加到列表中，按 i 的顺序插入到正确位置\n",
    "        chunk_text[i] = text\n",
    "\n",
    "print(len(chunk_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': '空空道人', 'dialogue': '空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍', 'action': '独白'}, {'role': '空空道人', 'dialogue': '因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨', 'action': '独白'}, {'role': '空空道人', 'dialogue': '及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷', 'action': '独白'}, {'role': '空空道人', 'dialogue': '实非别书之可比', 'action': '独白'}, {'role': '空空道人', 'dialogue': '虽其中大旨谈情，亦不过实录其事，又非假拟妄称，一味淫邀艳约，私订偷盟之可比', 'action': '独白'}, {'role': '空空道人', 'dialogue': '因毫不干涉时世，方从头至尾抄录回来，问世传奇', 'action': '独白'}, {'role': '空空道人', 'dialogue': '因空见色，由色生情，传情入色，自色悟空', 'action': '独白'}, {'role': '空空道人', 'dialogue': '空空道人遂易名为情僧，改《石头记》为《情僧录》', 'action': '独白'}, {'role': '空空道人', 'dialogue': '至?玉峰题曰《红楼梦》', 'action': '独白'}, {'role': '空空道人', 'dialogue': '东鲁孔梅溪则题曰《风月宝鉴》', 'action': '独白'}, {'role': '空空道人', 'dialogue': '后因曹雪芹于悼红轩中，披阅十载，增删五次，纂成目录，分出章回', 'action': '独白'}, {'role': '空空道人', 'dialogue': '则题曰《金陵十二钗》，并题一绝云：满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？', 'action': '独白'}, {'role': '空空道人', 'dialogue': '至脂砚斋甲戌抄阅再评，仍用《石头记》', 'action': '独白'}, {'role': '空空道人', 'dialogue': '出则既明，且看石上是何故事', 'action': '独白'}, {'role': '空空道人', 'dialogue': '按那石上书云：当日地陷东南，这东南一隅有处曰姑苏，有城曰阊门者，最是红尘中一二等富贵风流之地', 'action': '独白'}, {'role': '空空道人', 'dialogue': '这阊门外有个十里街，街内有个仁清巷，巷内有个古庙，因地方窄狭，人皆呼作葫芦庙', 'action': '独白'}, {'role': '空空道人', 'dialogue': '庙旁住着一家乡宦，姓甄名费，字士隐', 'action': '独白'}, {'role': '空空道人', 'dialogue': '嫡妻封氏，情性贤淑，深明礼义', 'action': '独白'}, {'role': '空空道人', 'dialogue': '家中虽不甚富贵，然本地便也推他为望族了', 'action': '独白'}, {'role': '空空道人', 'dialogue': '只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐', 'action': '独白'}, {'role': '空空道人', 'dialogue': '倒是神仙一流人品', 'action': '独白'}, {'role': '空空道人', 'dialogue': '只是一件不足：如今年已半百，膝下无儿，只有一女，乳名英莲，年方三岁', 'action': '独白'}]\n",
      "['空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍', '因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨', '及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷', '实非别书之可比', '虽其中大旨谈情，亦不过实录其事，又非假拟妄称，一味淫邀艳约，私订偷盟之可比', '因毫不干涉时世，方从头至尾抄录回来，问世传奇', '因空见色，由色生情，传情入色，自色悟空', '空空道人遂易名为情僧，改《石头记》为《情僧录》', '至?玉峰题曰《红楼梦》', '东鲁孔梅溪则题曰《风月宝鉴》', '后因曹雪芹于悼红轩中，披阅十载，增删五次，纂成目录，分出章回', '则题曰《金陵十二钗》，并题一绝云：满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？', '至脂砚斋甲戌抄阅再评，仍用《石头记》', '出则既明，且看石上是何故事', '按那石上书云：当日地陷东南，这东南一隅有处曰姑苏，有城曰阊门者，最是红尘中一二等富贵风流之地', '这阊门外有个十里街，街内有个仁清巷，巷内有个古庙，因地方窄狭，人皆呼作葫芦庙', '庙旁住着一家乡宦，姓甄名费，字士隐', '嫡妻封氏，情性贤淑，深明礼义', '家中虽不甚富贵，然本地便也推他为望族了', '只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐', '倒是神仙一流人品', '只是一件不足：如今年已半百，膝下无儿，只有一女，乳名英莲，年方三岁']\n",
      "['空空道人重新审视《石头记》，认为其内容并非单纯的时世批评。', '书中强调君仁臣良、父慈子孝等伦理道德，称功颂德。', '书中虽有情感描写，但实录其事，非虚构淫乱之作。', '空空道人将书名改为《情僧录》，并由玉峰题为《红楼梦》。', '东鲁孔梅溪题为《风月宝鉴》，曹雪芹在悼红轩增删五次，最终定名《金陵十二钗》。', '曹雪芹的绝句表达了对作品的感慨与深意。', '书中提到的故事背景设定在东南的姑苏，阊门外的仁清巷。', '主要人物甄士隐，性情淡泊，热爱自然，膝下无儿，只有一女英莲。']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id = 2\n",
    "dialoge_file = os.path.join(folder_path, f\"{id}_dialogue.txt\")\n",
    "summarzie_file = os.path.join(folder_path, f\"{id}_sum.txt\")\n",
    "raw_text = chunk_text[id]\n",
    "chunk_sum = []\n",
    "unique_chunk_sum = []\n",
    "# 给定summarzie_file = os.path.join(save_folder, f\"{id}_sum.txt\")\n",
    "\n",
    "# 先检查这个文件是否存在\n",
    "\n",
    "# 然后使用utf-8编码打开，检查每一行，如果strip后，行首是'-'，则把后面的字符串append到一个list chunk_sum中\n",
    "\n",
    "# 请用python为我实现\n",
    "if os.path.exists(summarzie_file):\n",
    "    with open(summarzie_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip().startswith(\"-\"):\n",
    "                chunk_sum.append(line.strip()[1:].strip())\n",
    "if os.path.exists(dialoge_file):\n",
    "    with open(dialoge_file, encoding=\"utf-8\") as f:\n",
    "        dialogues = []\n",
    "        for line in f:\n",
    "            dialogue = json.loads(line)\n",
    "            dialogues.append(dialogue)\n",
    "\n",
    "unique_dialogue = []\n",
    "for item in dialogues:\n",
    "    if item not in unique_dialogue:\n",
    "        unique_dialogue.append(item)\n",
    "dia_texts = [data[\"dialogue\"] for data in unique_dialogue]\n",
    "for item in chunk_sum:\n",
    "    if item not in unique_chunk_sum:\n",
    "        unique_chunk_sum.append(item)\n",
    "\n",
    "chunk_sum = unique_chunk_sum\n",
    "dialogues = unique_dialogue\n",
    "print(dialogues)\n",
    "print(dia_texts)\n",
    "print(chunk_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# 给定长文本raw_text。\n",
    "\n",
    "# 使用换行符\\n或者。 来对这个字符串进行切割，忽略掉strip之后是空的子字符串\n",
    "\n",
    "# 将每一段话的起点位置存储在一个list of int , starts中\n",
    "\n",
    "# 将每一段话的结束位置存储在一个list of int , ends中\n",
    "\n",
    "# 并且将每一个子字符串的存储在一个list of str, lines中\n",
    "def divide_raw2lines(raw_text):\n",
    "    previous_str = \"\"\n",
    "    starts = []\n",
    "    ends = []\n",
    "    lines = []\n",
    "    for i in range(len(raw_text)):\n",
    "        previous_str += raw_text[i]\n",
    "        if raw_text[i] in (\"\\n\", \"。\"):\n",
    "            strip_str = previous_str.strip(' \"“”\\r\\n')\n",
    "            if len(strip_str) > 0:\n",
    "                lines.append(strip_str)\n",
    "                starts.append(i - len(strip_str))\n",
    "                ends.append(i)\n",
    "            previous_str = \"\"\n",
    "        else:\n",
    "            pass\n",
    "    return lines, starts, ends\n",
    "\n",
    "\n",
    "lines, starts, ends = divide_raw2lines(raw_text)\n",
    "\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已知if '\\u4e00' <= char <= '\\u9fa5': 可以判断一个char是否是中文字\n",
    "\n",
    "# 我希望实现一个函数，这个函数的输入是两个list of string, 长度为M的query 和 长度为N的datas\n",
    "\n",
    "# 输出是一个M*N的numpy float数组 recalls\n",
    "\n",
    "# 先计算freqs[m][n] 表示query的第m句中的每一个中文字，是否在datas[n]中是否出现，如果出现，则freqs[m][n]加一\n",
    "\n",
    "# 然后计算recalls[m][n]是freqs[m][n]除掉 query[m]中所有中文字的个数\n",
    "import numpy as np\n",
    "\n",
    "def compute_char_recall(query, datas):\n",
    "    M = len(query)\n",
    "    N = len(datas)\n",
    "\n",
    "    freqs = np.zeros((M, N), dtype=int)\n",
    "\n",
    "    for m in range(M):\n",
    "        q_chars = set()\n",
    "        for char in query[m]:\n",
    "            if \"\\u4e00\" <= char <= \"\\u9fa5\":\n",
    "                q_chars.add(char)\n",
    "\n",
    "        for n in range(N):\n",
    "            for char in q_chars:\n",
    "                if char in datas[n]:\n",
    "                    freqs[m][n] += 1\n",
    "\n",
    "    query_chars_count = [\n",
    "        len(set(char for char in sent if \"\\u4e00\" <= char <= \"\\u9fa5\"))\n",
    "        for sent in query\n",
    "    ]\n",
    "\n",
    "    recalls = freqs / np.array(query_chars_count)[:, None]\n",
    "\n",
    "    return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.991911197261741 [1, 2, 3, 4, 6, 8, 12, 17]\n",
      "\n",
      "###\n",
      "空空道人重新审视《石头记》，认为其内容并非单纯的时世批评。\n",
      "\n",
      "\n",
      "空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍，因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨；及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷，实非别书之可比。\n",
      "\n",
      "###\n",
      "书中强调君仁臣良、父慈子孝等伦理道德，称功颂德。\n",
      "\n",
      "\n",
      "虽其中大旨谈情，亦不过实录其事，又非假拟妄称，一味淫邀艳约，私订偷盟之可比。\n",
      "\n",
      "###\n",
      "书中虽有情感描写，但实录其事，非虚构淫乱之作。\n",
      "\n",
      "\n",
      "因毫不干涉时世，方从头至尾抄录回来，问世传奇。\n",
      "\n",
      "###\n",
      "空空道人将书名改为《情僧录》，并由玉峰题为《红楼梦》。\n",
      "\n",
      "\n",
      "因空见色，由色生情，传情入色，自色悟空，空空道人遂易名为情僧，改《石头记》为《情僧录》。\n",
      "\n",
      "###\n",
      "东鲁孔梅溪题为《风月宝鉴》，曹雪芹在悼红轩增删五次，最终定名《金陵十二钗》。\n",
      "\n",
      "\n",
      "至?玉峰题曰《红楼梦》。\n",
      "东鲁孔梅溪则题曰《风月宝鉴》。\n",
      "\n",
      "###\n",
      "曹雪芹的绝句表达了对作品的感慨与深意。\n",
      "\n",
      "\n",
      "后因曹雪芹于悼红轩中，披阅十载，增删五次，纂成目录，分出章回，则题曰《金陵十二钗》，并题一绝云：\n",
      "满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？\n",
      "\n",
      "###\n",
      "书中提到的故事背景设定在东南的姑苏，阊门外的仁清巷。\n",
      "\n",
      "\n",
      "至脂砚斋甲戌抄阅再评，仍用《石头记》。\n",
      "出则既明，且看石上是何故事。\n",
      "按那石上书云：\n",
      "当日地陷东南，这东南一隅有处曰姑苏，有城曰阊门者，最是红尘中一二等富贵风流之地。\n",
      "\n",
      "###\n",
      "主要人物甄士隐，性情淡泊，热爱自然，膝下无儿，只有一女英莲。\n",
      "\n",
      "\n",
      "这阊门外有个十里街，街内有个仁清巷，巷内有个古庙，因地方窄狭，人皆呼作葫芦庙。\n",
      "庙旁住着一家乡宦，姓甄名费，字士隐。\n",
      "嫡妻封氏，情性贤淑，深明礼义。\n",
      "家中虽不甚富贵，然本地便也推他为望族了。\n",
      "只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐，倒是神仙一流人品。\n"
     ]
    }
   ],
   "source": [
    "# import copy\n",
    "def summary2line(chunk_sum, lines):\n",
    "\n",
    "    s = compute_char_recall(chunk_sum, lines)\n",
    "\n",
    "    color_map = {}\n",
    "    ans_Q = {}\n",
    "\n",
    "    ans_div = {}\n",
    "\n",
    "    flags = {}\n",
    "\n",
    "    M = len(chunk_sum)\n",
    "    N = len(lines)\n",
    "\n",
    "    for n in range(0, N):\n",
    "        if n == 0:\n",
    "            ans_Q[(0, 0)] = s[0, 0]\n",
    "            ans_div[(0, 0)] = []\n",
    "        else:\n",
    "            ans_Q[(0, n)] = ans_Q[(0, n - 1)] + s[0, n]\n",
    "            ans_div[(0, n)] = []\n",
    "\n",
    "    for m in range(1, M):\n",
    "        ans_Q[(m, m)] = ans_Q[(m - 1, m - 1)] + s[m, m]\n",
    "        ans_div[(m, m)] = ans_div[(m - 1, m - 1)].copy()\n",
    "        ans_div[(m, m)].append(m)\n",
    "\n",
    "    def find_Q(m, n):\n",
    "        # print(m,n)\n",
    "\n",
    "        if m < 0 or n < 0:\n",
    "            print(\"error out bound\", m, \" \", n)\n",
    "            return 0, []\n",
    "\n",
    "        if (m, n) in ans_Q.keys():\n",
    "            return ans_Q[(m, n)], ans_div[(m, n)]\n",
    "\n",
    "        if (m, n) in color_map.keys():\n",
    "            print(\"error repeated quest \", m, \" \", n)\n",
    "            return 0, []\n",
    "        else:\n",
    "            color_map[(m, n)] = 1\n",
    "\n",
    "        current_div = []\n",
    "\n",
    "        left, left_div = find_Q(m, n - 1)\n",
    "        right, right_div = find_Q(m - 1, n - 1)\n",
    "\n",
    "        if left > right:\n",
    "            ans = left + s[m][n]\n",
    "            flags[(m, n)] = False\n",
    "            current_div = left_div\n",
    "\n",
    "        else:\n",
    "            ans = right + s[m][n]\n",
    "            flags[(m, n)] = True\n",
    "            current_div = right_div.copy()\n",
    "            current_div.append(n - 1)\n",
    "\n",
    "        # ans = max(  , ) + s[m][n]\n",
    "\n",
    "        ans_Q[(m, n)] = ans\n",
    "        ans_div[(m, n)] = current_div.copy()\n",
    "\n",
    "        return ans, current_div\n",
    "\n",
    "    # print(find_Q(0,5))\n",
    "    # print(find_Q(M-1,N-1))\n",
    "\n",
    "    score, divs = find_Q(M - 1, N - 1)\n",
    "    divs.append(N - 1)\n",
    "\n",
    "    return score, divs\n",
    "\n",
    "\n",
    "score, divs = summary2line(chunk_sum, lines)\n",
    "print(score, divs)\n",
    "\n",
    "last = 0\n",
    "\n",
    "# divs.append(N-1)\n",
    "\n",
    "for i, div in enumerate(divs):\n",
    "    print(\"\\n###\")\n",
    "    print(chunk_sum[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    for j in range(last, div):\n",
    "        print(lines[j])\n",
    "        last = div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 16, 17]\n",
      "\n",
      "###\n",
      "空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍\n",
      "空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍，因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨；及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷，实非别书之可比。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨\n",
      "空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍，因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨；及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷，实非别书之可比。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷\n",
      "空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍，因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨；及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷，实非别书之可比。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "实非别书之可比\n",
      "空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍，因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨；及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷，实非别书之可比。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "虽其中大旨谈情，亦不过实录其事，又非假拟妄称，一味淫邀艳约，私订偷盟之可比\n",
      "虽其中大旨谈情，亦不过实录其事，又非假拟妄称，一味淫邀艳约，私订偷盟之可比。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "因毫不干涉时世，方从头至尾抄录回来，问世传奇\n",
      "因毫不干涉时世，方从头至尾抄录回来，问世传奇。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "因空见色，由色生情，传情入色，自色悟空\n",
      "因空见色，由色生情，传情入色，自色悟空，空空道人遂易名为情僧，改《石头记》为《情僧录》。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "空空道人遂易名为情僧，改《石头记》为《情僧录》\n",
      "因空见色，由色生情，传情入色，自色悟空，空空道人遂易名为情僧，改《石头记》为《情僧录》。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "至?玉峰题曰《红楼梦》\n",
      "至?玉峰题曰《红楼梦》。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "东鲁孔梅溪则题曰《风月宝鉴》\n",
      "东鲁孔梅溪则题曰《风月宝鉴》。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "后因曹雪芹于悼红轩中，披阅十载，增删五次，纂成目录，分出章回\n",
      "后因曹雪芹于悼红轩中，披阅十载，增删五次，纂成目录，分出章回，则题曰《金陵十二钗》，并题一绝云：\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "则题曰《金陵十二钗》，并题一绝云：满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？\n",
      "满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "至脂砚斋甲戌抄阅再评，仍用《石头记》\n",
      "至脂砚斋甲戌抄阅再评，仍用《石头记》。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "出则既明，且看石上是何故事\n",
      "出则既明，且看石上是何故事。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "按那石上书云：当日地陷东南，这东南一隅有处曰姑苏，有城曰阊门者，最是红尘中一二等富贵风流之地\n",
      "当日地陷东南，这东南一隅有处曰姑苏，有城曰阊门者，最是红尘中一二等富贵风流之地。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "这阊门外有个十里街，街内有个仁清巷，巷内有个古庙，因地方窄狭，人皆呼作葫芦庙\n",
      "这阊门外有个十里街，街内有个仁清巷，巷内有个古庙，因地方窄狭，人皆呼作葫芦庙。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "庙旁住着一家乡宦，姓甄名费，字士隐\n",
      "庙旁住着一家乡宦，姓甄名费，字士隐。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "嫡妻封氏，情性贤淑，深明礼义\n",
      "嫡妻封氏，情性贤淑，深明礼义。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "家中虽不甚富贵，然本地便也推他为望族了\n",
      "家中虽不甚富贵，然本地便也推他为望族了。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐\n",
      "只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐，倒是神仙一流人品。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "倒是神仙一流人品\n",
      "只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐，倒是神仙一流人品。\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "只是一件不足：如今年已半百，膝下无儿，只有一女，乳名英莲，年方三岁\n",
      "只是一件不足：如今年已半百，膝下无儿，只有一女，乳名英莲，年方三岁。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def dialogue2line(dia_texts, lines):\n",
    "    s_dialogue = compute_char_recall(dia_texts, lines)\n",
    "\n",
    "    M, N = s_dialogue.shape\n",
    "    if M == 0 or N == 0:\n",
    "        return []\n",
    "    dp = np.zeros((M, N))\n",
    "    dp[0] = s_dialogue[0]\n",
    "    prev_indices = np.zeros((M, N), dtype=int)\n",
    "    for i in range(1, M):\n",
    "        for j in range(N):\n",
    "            max_prev_index = np.argmax(dp[i - 1])\n",
    "            dp[i][j] = dp[i - 1][max_prev_index] + s_dialogue[i][j]\n",
    "            prev_indices[i][j] = max_prev_index\n",
    "\n",
    "    max_end_index = np.argmax(dp[-1])\n",
    "    sequence = []\n",
    "    for i in range(M - 1, -1, -1):\n",
    "        sequence.append(max_end_index)\n",
    "        max_end_index = prev_indices[i][max_end_index]\n",
    "    sequence.reverse()\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\n",
    "seq = dialogue2line(dia_texts, lines)\n",
    "print(seq)\n",
    "\n",
    "for i, id in enumerate(seq):\n",
    "    print(\"\\n###\")\n",
    "    print(dia_texts[i])\n",
    "    print(lines[id])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    for j in range(last, div):\n",
    "        print(lines[j])\n",
    "        last = div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[1, 2, 3, 4, 6, 8, 12, 17]\n",
      "['空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍', '因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨', '及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷', '实非别书之可比', '虽其中大旨谈情，亦不过实录其事，又非假拟妄称，一味淫邀艳约，私订偷盟之可比', '因毫不干涉时世，方从头至尾抄录回来，问世传奇', '因空见色，由色生情，传情入色，自色悟空', '空空道人遂易名为情僧，改《石头记》为《情僧录》', '至?玉峰题曰《红楼梦》', '东鲁孔梅溪则题曰《风月宝鉴》', '后因曹雪芹于悼红轩中，披阅十载，增删五次，纂成目录，分出章回', '则题曰《金陵十二钗》，并题一绝云：满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？', '至脂砚斋甲戌抄阅再评，仍用《石头记》', '出则既明，且看石上是何故事', '按那石上书云：当日地陷东南，这东南一隅有处曰姑苏，有城曰阊门者，最是红尘中一二等富贵风流之地', '这阊门外有个十里街，街内有个仁清巷，巷内有个古庙，因地方窄狭，人皆呼作葫芦庙', '庙旁住着一家乡宦，姓甄名费，字士隐', '嫡妻封氏，情性贤淑，深明礼义', '家中虽不甚富贵，然本地便也推他为望族了', '只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐', '倒是神仙一流人品', '只是一件不足：如今年已半百，膝下无儿，只有一女，乳名英莲，年方三岁']\n",
      "[0, 0, 0, 0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 16, 17]\n",
      "[{'role': '空空道人', 'text': '空空道人听如此说，思忖半晌，将一这《石头记》再检阅一遍', 'if_scene': False}, {'role': '空空道人', 'text': '因见上面虽有些指奸责佞、贬恶诛邪之语，亦非伤时骂世之旨', 'if_scene': False}, {'role': '空空道人', 'text': '及至君仁臣良、父慈子孝，凡伦常所关之处，皆是称功颂德，眷眷无穷', 'if_scene': False}, {'role': '空空道人', 'text': '实非别书之可比', 'if_scene': False}, {'role': '空空道人', 'text': '虽其中大旨谈情，亦不过实录其事，又非假拟妄称，一味淫邀艳约，私订偷盟之可比', 'if_scene': False}, {'role': 'scene', 'text': '空空道人重新审视《石头记》，认为其内容并非单纯的时世批评。', 'if_scene': True}, {'role': '空空道人', 'text': '因毫不干涉时世，方从头至尾抄录回来，问世传奇', 'if_scene': False}, {'role': 'scene', 'text': '书中强调君仁臣良、父慈子孝等伦理道德，称功颂德。', 'if_scene': True}, {'role': '空空道人', 'text': '因空见色，由色生情，传情入色，自色悟空', 'if_scene': False}, {'role': 'scene', 'text': '书中虽有情感描写，但实录其事，非虚构淫乱之作。', 'if_scene': True}, {'role': '空空道人', 'text': '空空道人遂易名为情僧，改《石头记》为《情僧录》', 'if_scene': False}, {'role': '空空道人', 'text': '至?玉峰题曰《红楼梦》', 'if_scene': False}, {'role': 'scene', 'text': '空空道人将书名改为《情僧录》，并由玉峰题为《红楼梦》。', 'if_scene': True}, {'role': '空空道人', 'text': '东鲁孔梅溪则题曰《风月宝鉴》', 'if_scene': False}, {'role': '空空道人', 'text': '后因曹雪芹于悼红轩中，披阅十载，增删五次，纂成目录，分出章回', 'if_scene': False}, {'role': 'scene', 'text': '东鲁孔梅溪题为《风月宝鉴》，曹雪芹在悼红轩增删五次，最终定名《金陵十二钗》。', 'if_scene': True}, {'role': '空空道人', 'text': '则题曰《金陵十二钗》，并题一绝云：满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？', 'if_scene': False}, {'role': '空空道人', 'text': '至脂砚斋甲戌抄阅再评，仍用《石头记》', 'if_scene': False}, {'role': 'scene', 'text': '曹雪芹的绝句表达了对作品的感慨与深意。', 'if_scene': True}, {'role': '空空道人', 'text': '出则既明，且看石上是何故事', 'if_scene': False}, {'role': '空空道人', 'text': '按那石上书云：当日地陷东南，这东南一隅有处曰姑苏，有城曰阊门者，最是红尘中一二等富贵风流之地', 'if_scene': False}, {'role': '空空道人', 'text': '这阊门外有个十里街，街内有个仁清巷，巷内有个古庙，因地方窄狭，人皆呼作葫芦庙', 'if_scene': False}, {'role': 'scene', 'text': '书中提到的故事背景设定在东南的姑苏，阊门外的仁清巷。', 'if_scene': True}, {'role': '空空道人', 'text': '庙旁住着一家乡宦，姓甄名费，字士隐', 'if_scene': False}, {'role': '空空道人', 'text': '嫡妻封氏，情性贤淑，深明礼义', 'if_scene': False}, {'role': '空空道人', 'text': '家中虽不甚富贵，然本地便也推他为望族了', 'if_scene': False}, {'role': '空空道人', 'text': '只因这甄士隐禀性恬淡，不以功名为念，每日只以观花修竹、酌酒吟诗为乐', 'if_scene': False}, {'role': '空空道人', 'text': '倒是神仙一流人品', 'if_scene': False}, {'role': '空空道人', 'text': '只是一件不足：如今年已半百，膝下无儿，只有一女，乳名英莲，年方三岁', 'if_scene': False}, {'role': 'scene', 'text': '主要人物甄士隐，性情淡泊，热爱自然，膝下无儿，只有一女英莲。', 'if_scene': True}]\n"
     ]
    }
   ],
   "source": [
    "print(len(chunk_sum))\n",
    "print(divs)\n",
    "print(dia_texts)\n",
    "print(seq)\n",
    "\n",
    "\n",
    "# string_indices = [10, 11]\n",
    "def jsonl_sorted(chunk_sum, divs, dia_texts, seq):\n",
    "\n",
    "    combined_data = []\n",
    "    combined_text = \"\"\n",
    "    for index in sorted(seq + divs):\n",
    "        # print(index)\n",
    "        if index in seq:\n",
    "\n",
    "            combined_data.append(\n",
    "                {\n",
    "                    \"role\": dialogues[seq.index(index)][\"role\"],\n",
    "                    \"text\": dialogues[seq.index(index)][\"dialogue\"],\n",
    "                    \"if_scene\": False,\n",
    "                }\n",
    "            )\n",
    "            combined_text = (\n",
    "                combined_text\n",
    "                + dialogues[seq.index(index)][\"role\"]\n",
    "                + \":\"\n",
    "                + dialogues[seq.index(index)][\"dialogue\"]\n",
    "                + \"\\n\"\n",
    "            )\n",
    "            seq[seq.index(index)] = -1\n",
    "        if index in divs:\n",
    "            combined_data.append(\n",
    "                {\n",
    "                    \"role\": \"scene\",\n",
    "                    \"text\": chunk_sum[divs.index(index)],\n",
    "                    \"if_scene\": True,\n",
    "                }\n",
    "            )\n",
    "            combined_text = (\n",
    "                combined_text + \"scene\" + \":\" + chunk_sum[divs.index(index)] + \"\\n\"\n",
    "            )\n",
    "            divs[divs.index(index)] = -1\n",
    "\n",
    "    return combined_data, combined_text\n",
    "\n",
    "\n",
    "combined_data, combined_text = jsonl_sorted(\n",
    "    chunk_sum, divs.copy(), dia_texts, seq.copy()\n",
    ")\n",
    "print(combined_data)\n",
    "# 打开文件，以写入模式（\"w\"）打开\n",
    "with open(dialoge_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    # 遍历数据列表中的每个字典\n",
    "    for record in combined_data:\n",
    "        # 将字典转换为JSON格式的字符串\n",
    "        json_record = json.dumps(record, ensure_ascii=False)\n",
    "        # 将转换后的JSON字符串写入文件，并添加换行符\n",
    "        file.write(json_record + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm -rf {save_folder_path}\")\n",
    "os.makedirs(save_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 16/958 [00:00<00:06, 154.61item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2个chunk出错\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|██▉       | 285/958 [00:02<00:04, 142.13item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第260个chunk出错\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|████▎     | 412/958 [00:03<00:03, 138.99item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第400个chunk出错\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  76%|███████▌  | 727/958 [00:05<00:02, 92.00item/s] C:\\Users\\charles0618\\AppData\\Local\\Temp\\ipykernel_32624\\1180376461.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  recalls = freqs / np.array(query_chars_count)[:, None]\n",
      "Processing: 100%|██████████| 958/958 [00:07<00:00, 122.94item/s]\n"
     ]
    }
   ],
   "source": [
    "final_jsonl = []\n",
    "final_txt = \"\"\n",
    "\n",
    "for i in tqdm(\n",
    "    range(1, len(chunk_text)), desc=\"Processing\", total=len(chunk_text) - 1, unit=\"item\"\n",
    "):\n",
    "\n",
    "    try:\n",
    "        # story_name_en = 'shediaoyingxiongzhuan'\n",
    "        raw_text = chunk_text[i]\n",
    "\n",
    "        import os\n",
    "\n",
    "        save_folder = f\"./extract/{story_name_en}\"\n",
    "\n",
    "        dialoge_file = os.path.join(save_folder, f\"{i}_dialogue.txt\")\n",
    "        summarzie_file = os.path.join(save_folder, f\"{i}_sum.txt\")\n",
    "\n",
    "        chunk_sum = []\n",
    "        unique_chunk_sum = []\n",
    "        if os.path.exists(summarzie_file):\n",
    "            with open(summarzie_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if line.strip().startswith(\"-\"):\n",
    "                        chunk_sum.append(line.strip()[1:].strip())\n",
    "        if os.path.exists(dialoge_file):\n",
    "            with open(dialoge_file, encoding=\"utf-8\") as f:\n",
    "                dialogues = []\n",
    "                for line in f:\n",
    "                    dialogue = json.loads(line)\n",
    "                    dialogues.append(dialogue)\n",
    "\n",
    "        unique_dialogue = []\n",
    "        for item in dialogues:\n",
    "            if item not in unique_dialogue:\n",
    "                unique_dialogue.append(item)\n",
    "        dia_texts = [data[\"dialogue\"] for data in unique_dialogue]\n",
    "        for item in chunk_sum:\n",
    "            if item not in unique_chunk_sum:\n",
    "                unique_chunk_sum.append(item)\n",
    "\n",
    "        chunk_sum = unique_chunk_sum\n",
    "        dialogues = unique_dialogue\n",
    "        lines, starts, ends = divide_raw2lines(raw_text)\n",
    "        # print(chunk_sum)\n",
    "        # print(lines)\n",
    "        score, divs = summary2line(chunk_sum, lines)  # summary匹配\n",
    "        seq = dialogue2line(dia_texts, lines)  # 对话匹配\n",
    "        combined_data, combined_text = jsonl_sorted(\n",
    "            chunk_sum, divs.copy(), dia_texts, seq.copy()\n",
    "        )\n",
    "        # 如果需要保存每个chunk的，在此处保存\n",
    "        final_jsonl.append(combined_data)\n",
    "        final_txt = final_txt + combined_text + \"\\n\"\n",
    "    except:\n",
    "        print(\"第\" + str(i) + \"个chunk出错\")\n",
    "        pass\n",
    "with open(save_jsonl_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    # 遍历数据列表中的每个字典\n",
    "    for record in final_jsonl:\n",
    "        # 将字典转换为JSON格式的字符串\n",
    "        json_record = json.dumps(record, ensure_ascii=False)\n",
    "        # 将转换后的JSON字符串写入文件，并添加换行符\n",
    "        file.write(json_record + \"\\n\")\n",
    "with open(save_txt_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(final_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.小说chatbot抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "\n",
    "# 支持跨越多少行寻找目标角色，也即控制段内行间距不超过该值\n",
    "max_find_lines = 10\n",
    "\n",
    "max_token_num = 500\n",
    "\n",
    "\n",
    "\n",
    "# 输入文件路径\n",
    "input_jsonl_name = (\n",
    "    f\"./reorganized/{novel_name}/reorganized_{novel_name}.jsonl\"\n",
    ")\n",
    "\n",
    "# 保存路径\n",
    "savepath = f\"./role/{novel_name}\"\n",
    "os.system(f\"rm -rf {savepath}\")\n",
    "os.makedirs(savepath, exist_ok=True)\n",
    "# zip_path = '/content/linghuchong_text.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26970\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "data_in_chunk = []\n",
    "with open(input_jsonl_name, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        data_in_chunk.append(json.loads(line))\n",
    "\n",
    "data = []\n",
    "\n",
    "for chunk in data_in_chunk:\n",
    "    for d in chunk:\n",
    "        data.append(d)\n",
    "\n",
    "print(len(data))\n",
    "for i, d in enumerate(data):\n",
    "    if d[\"role\"] == \"scene\":\n",
    "        first_scene_id = i\n",
    "        break\n",
    "print(first_scene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_scene_chat_id(data, target_role_single):\n",
    "\n",
    "    chat_ids = []\n",
    "\n",
    "    # 先寻找所有出现角色的节点\n",
    "    for i, d in enumerate(data):\n",
    "        if d[\"role\"] == target_role_single:\n",
    "            chat_ids.append(i)\n",
    "\n",
    "    previous_scene_ids = []\n",
    "\n",
    "    # 对于每一个chat_ids，向前寻找scene的节点\n",
    "    for chat_id in chat_ids:\n",
    "        ans = first_scene_id\n",
    "        for j in range(chat_id, first_scene_id, -1):\n",
    "            if data[j][\"role\"] == \"scene\":\n",
    "                ans = j\n",
    "                break\n",
    "        previous_scene_ids.append(ans)\n",
    "    return chat_ids, previous_scene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_chats2chunks(chat_ids, previous_scene_ids):\n",
    "    chat_ids_in_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for chat_id in chat_ids:\n",
    "        if not current_chunk:\n",
    "            current_chunk.append(chat_id)\n",
    "            continue\n",
    "\n",
    "        if chat_id - current_chunk[-1] <= max_find_lines:\n",
    "            current_chunk.append(chat_id)\n",
    "        else:\n",
    "            chat_ids_in_chunk.append(current_chunk)\n",
    "            current_chunk = [chat_id]\n",
    "\n",
    "    if current_chunk:\n",
    "        chat_ids_in_chunk.append(current_chunk)\n",
    "\n",
    "    # print(chat_ids_in_chunk[0])\n",
    "\n",
    "    chat_id2previous_scene_id = {}\n",
    "\n",
    "    for previous, chat_id in zip(previous_scene_ids, chat_ids):\n",
    "        chat_id2previous_scene_id[chat_id] = previous\n",
    "        if previous > 0:\n",
    "            if data[previous - 1][\"role\"] != target_role:\n",
    "                chat_id2previous_scene_id[chat_id] -= 1\n",
    "    return chat_ids_in_chunk, chat_id2previous_scene_id\n",
    "\n",
    "\n",
    "# chat_ids的分块， chat_id对应的旁白id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_token(my_str):\n",
    "    return len(enc.encode(my_str))\n",
    "\n",
    "\n",
    "def data2str(data):\n",
    "    role = data[\"role\"]\n",
    "    if role in [\"旁白\", \"\", \"scene\", \"Scene\", \"narrator\", \"Narrator\"]:\n",
    "        return \"scene:\" + data[\"text\"]\n",
    "    else:\n",
    "        return role + \":「\" + data[\"text\"] + \"」\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2texts(data, chat_ids_in_chunk, chat_id2previous_scene_id):\n",
    "    line_token = [count_token(data2str(d)) for d in data]\n",
    "    from ast import Break\n",
    "\n",
    "    final_chunks = []\n",
    "\n",
    "    print_count = 0\n",
    "\n",
    "    appended_key = []\n",
    "\n",
    "    for chunk in chat_ids_in_chunk:\n",
    "        N = len(chunk)\n",
    "\n",
    "        current_i = 0\n",
    "\n",
    "        while current_i < N - 1:\n",
    "\n",
    "            consider_chat_id = chunk[current_i]\n",
    "\n",
    "            previous_scene_id = chat_id2previous_scene_id[consider_chat_id]\n",
    "\n",
    "            # 保底\n",
    "            withdraw_start = previous_scene_id\n",
    "            withdraw_end = consider_chat_id\n",
    "\n",
    "            current_count = sum(line_token[previous_scene_id : consider_chat_id + 1])\n",
    "            while current_count < max_token_num and current_i < N - 1:\n",
    "                consider_end = chunk[current_i + 1]\n",
    "                consider_count = sum(line_token[previous_scene_id : consider_end + 1])\n",
    "                if consider_count < max_token_num:\n",
    "                    current_count = consider_count\n",
    "                    withdraw_start = previous_scene_id\n",
    "                    withdraw_end = consider_end\n",
    "                    current_i += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # print_count += 1\n",
    "\n",
    "            # print(withdraw_start, end = ' ')\n",
    "            # if print_count % 5 == 0:\n",
    "            #     print()\n",
    "\n",
    "            if withdraw_end + 1 not in appended_key:\n",
    "                appended_key.append(withdraw_end + 1)\n",
    "                chunk_str = \"\"\n",
    "                for i in range(withdraw_start, withdraw_end + 1):\n",
    "                    chunk_str += data2str(data[i]) + \"\\n\"\n",
    "\n",
    "                final_chunks.append(chunk_str)\n",
    "\n",
    "            current_i += 1\n",
    "    return appended_key, final_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def save_chunk2zip(savepath, save_title, final_chunks):\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    for i in range(0, len(final_chunks)):\n",
    "        my_str = final_chunks[i]\n",
    "        with open(savepath + f\"/text_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(my_str)\n",
    "    zip_path = \"./role/\" + save_title + \"_text.zip\"\n",
    "    with zipfile.ZipFile(zip_path, \"w\") as zipf:\n",
    "        for filename in os.listdir(savepath):\n",
    "            zipf.write(savepath + \"/\" + filename)\n",
    "\n",
    "    print(\"Zipped folder saved to\", zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped folder saved to ./role/黛玉_text.zip\n",
      "Zipped folder saved to ./role/宝玉_text.zip\n",
      "Zipped folder saved to ./role/宝钗_text.zip\n"
     ]
    }
   ],
   "source": [
    "for role_cur_name in target_role:\n",
    "    chat_ids, previous_scene_ids = output_scene_chat_id(data, role_cur_name)\n",
    "    chat_ids_in_chunk, chat_id2previous_scene_id = divide_chats2chunks(\n",
    "        chat_ids, previous_scene_ids\n",
    "    )\n",
    "    appended_key, final_chunks = id2texts(\n",
    "        data, chat_ids_in_chunk, chat_id2previous_scene_id\n",
    "    )\n",
    "    save_chunk2zip(\n",
    "        savepath + \"/\" + role_cur_name, role_cur_name, final_chunks\n",
    "    )  # 如果你想修改保存的zip名称，请修改本函数的第二个参数save_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.抽取embedding\n",
    "获得角色的jsonl资料后需要进行embedding构建支持RAG的知识库，这一步移到test文件里进行了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatRolePlay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
